{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trina-SE/Text_to_Python/blob/main/colab_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: CodeSearchNet Python\n",
        "\n",
        "# Model:\n",
        "\n",
        "# Vanilla RNN Seq2Seq\n",
        "# LSTM Seq2Seq\n",
        "# LSTM + Bahdanau Attention\n",
        "# Output folder:\n",
        "\n",
        "# outputs/ (loss curves + metrics)\n",
        "# checkpoints/ (best model)\n",
        "# figures/ (attention heatmaps)"
      ],
      "metadata": {
        "id": "SIVIQ5qn-u9e"
      },
      "id": "SIVIQ5qn-u9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec3d895",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bec3d895",
        "outputId": "13eb36b0-a2bc-4835-e6c1-e5e647471230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Text_to_Python'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 60 (delta 15), reused 42 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (60/60), 128.18 KiB | 2.33 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Trina-SE/Text_to_Python.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c893742-b779-498c-9f72-2a9ca45883ca",
        "id": "8muwPo60wJkW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Text_to_Python\n"
          ]
        }
      ],
      "source": [
        "%cd Text_to_Python"
      ],
      "id": "8muwPo60wJkW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e7926e",
      "metadata": {
        "id": "a4e7926e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a1e99d-74c4-47b0-945b-e7075ce8b145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# import dependency\n",
        "!pip -q install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a1a34f",
      "metadata": {
        "id": "56a1a34f"
      },
      "outputs": [],
      "source": [
        "# src add\n",
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ[\"PYTHONPATH\"] = os.path.abspath(\"src\")\n",
        "sys.path.append(os.path.abspath(\"src\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model train+evaluation+Attention Heatmaps\n",
        "# Train 8000/val 1000/ Test 1000/epochs 10\n",
        "\n",
        "!python run_all.py --device cuda --epochs 10 --train-size 8000 --val-size 1000 --test-size 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16kvaAx34jIF",
        "outputId": "aa7c67b6-8487-46d1-8ff4-de4ac3cdbcec"
      },
      "id": "16kvaAx34jIF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Filtering splits...\n",
            "Building examples (length filtering + truncation)...\n",
            "Loaded examples: train=8000 val=1000 test=1000\n",
            "epoch 1/10 train_loss=6.1552 val_loss=5.0294\n",
            "epoch 2/10 train_loss=5.5828 val_loss=4.9457\n",
            "epoch 3/10 train_loss=5.3457 val_loss=4.9869\n",
            "epoch 4/10 train_loss=5.2290 val_loss=5.0234\n",
            "epoch 5/10 train_loss=5.1339 val_loss=4.9600\n",
            "epoch 6/10 train_loss=5.0662 val_loss=4.9352\n",
            "epoch 7/10 train_loss=5.0167 val_loss=4.9383\n",
            "epoch 8/10 train_loss=4.9640 val_loss=4.9241\n",
            "epoch 9/10 train_loss=4.9041 val_loss=4.9767\n",
            "epoch 10/10 train_loss=4.8617 val_loss=4.9466\n",
            "Loading dataset...\n",
            "Filtering splits...\n",
            "Building examples (length filtering + truncation)...\n",
            "Loaded examples: train=8000 val=1000 test=1000\n",
            "Loading dataset...\n",
            "Filtering splits...\n",
            "Building examples (length filtering + truncation)...\n",
            "Loaded examples: train=8000 val=1000 test=1000\n",
            "epoch 1/10 train_loss=6.1014 val_loss=4.8976\n",
            "epoch 2/10 train_loss=5.4285 val_loss=4.7717\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/Text_to_Python/src/text2python/train.py\", line 182, in <module>\n",
            "    main()\n",
            "  File \"/content/Text_to_Python/src/text2python/train.py\", line 162, in main\n",
            "    train_loss = train_epoch(\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/content/Text_to_Python/src/text2python/train.py\", line 60, in train_epoch\n",
            "    logits = model(src, tgt, config.tgt_sos_idx, config.teacher_forcing)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 1264, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 2053, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 2011, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Text_to_Python/run_all.py\", line 70, in <module>\n",
            "    main()\n",
            "  File \"/content/Text_to_Python/run_all.py\", line 38, in main\n",
            "    run(base + [\"--model\", model])\n",
            "  File \"/content/Text_to_Python/run_all.py\", line 7, in run\n",
            "    result = subprocess.run(cmd, check=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 550, in run\n",
            "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 1201, in communicate\n",
            "    self.wait()\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 1277, in wait\n",
            "    self._wait(timeout=sigint_timeout)\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 2021, in _wait\n",
            "    def _wait(self, timeout):\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MP0hBjly4WWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853d8ebb-70d6-45b2-b3fc-6f190208bf31"
      },
      "id": "MP0hBjly4WWd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "439e5256",
      "metadata": {
        "id": "439e5256"
      },
      "outputs": [],
      "source": [
        "#Train model\n",
        "# RNN\n",
        "!python -m text2python.train --model rnn --device cuda --epochs 10\n",
        "\n",
        "# LSTM\n",
        "!python -m text2python.train --model lstm --device cuda --epochs 10\n",
        "\n",
        "# Attention\n",
        "!python -m text2python.train --model attention --device cuda --epochs 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880f8495",
      "metadata": {
        "id": "880f8495"
      },
      "outputs": [],
      "source": [
        "#Checkpoint evaluation\n",
        "!python -m text2python.eval --checkpoint checkpoints/rnn_best.pt --device cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef468bc",
      "metadata": {
        "id": "bef468bc"
      },
      "outputs": [],
      "source": [
        "#Attention heatmap\n",
        "!python -m text2python.attention --checkpoint checkpoints/attention_best.pt --indices 0 1 2 --device cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba4c56f",
      "metadata": {
        "id": "cba4c56f"
      },
      "outputs": [],
      "source": [
        "#save output to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ae77f7",
      "metadata": {
        "id": "a9ae77f7"
      },
      "outputs": [],
      "source": [
        "!cp -r outputs /content/drive/MyDrive/text2python_outputs\n",
        "!cp -r checkpoints /content/drive/MyDrive/text2python_checkpoints\n",
        "!cp -r figures /content/drive/MyDrive/text2python_figures"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}